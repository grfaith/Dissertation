{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPYFPuVWNfY6d52ND72upiJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/grfaith/Dissertation/blob/master/Finding_explore_kw_hits_in_AS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SY00mYewtFuU",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db7bc7e0-958c-4fb4-94df-03a365fe799a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.19.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: ipympl in /usr/local/lib/python3.10/dist-packages (0.9.4)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipympl) (0.2.0)\n",
            "Requirement already satisfied: ipython<9 in /usr/local/lib/python3.10/dist-packages (from ipympl) (7.34.0)\n",
            "Requirement already satisfied: ipywidgets<9,>=7.6.0 in /usr/local/lib/python3.10/dist-packages (from ipympl) (7.7.1)\n",
            "Requirement already satisfied: matplotlib<4,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from ipympl) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ipympl) (1.25.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from ipympl) (9.4.0)\n",
            "Requirement already satisfied: traitlets<6 in /usr/local/lib/python3.10/dist-packages (from ipympl) (5.7.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython<9->ipympl) (67.7.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython<9->ipympl) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython<9->ipympl) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython<9->ipympl) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython<9->ipympl) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython<9->ipympl) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython<9->ipympl) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython<9->ipympl) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython<9->ipympl) (4.9.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<9,>=7.6.0->ipympl) (5.5.6)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<9,>=7.6.0->ipympl) (3.6.6)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<9,>=7.6.0->ipympl) (3.0.10)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.4.0->ipympl) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.4.0->ipympl) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.4.0->ipympl) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.4.0->ipympl) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.4.0->ipympl) (24.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.4.0->ipympl) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.4.0->ipympl) (2.8.2)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (6.3.3)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython<9->ipympl) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython<9->ipympl) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython<9->ipympl) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib<4,>=3.4.0->ipympl) (1.16.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (6.5.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (3.1.4)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (24.0.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (23.1.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (5.7.2)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (6.5.4)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.6.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.20.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.0.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (4.2.2)\n",
            "Requirement already satisfied: jupyter-server>=1.8 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.24.0)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.2.4)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (4.9.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (4.12.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (2.1.5)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.10.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.3.0)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (2.19.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (4.19.2)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (21.2.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.18.1)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.8.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.16.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (2.5)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.5.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (3.7)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.2.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (2.22)\n"
          ]
        }
      ],
      "source": [
        "###Installs\n",
        "\n",
        "!pip install datasets\n",
        "!pip install ipympl\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is code for looking at a range of years in the American Stories data and finding articles which appear with the string 'explor' and saving their information to disk."
      ],
      "metadata": {
        "id": "ynmUlyRjtbwb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Imports\n",
        "import json\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "import tqdm as tq\n",
        "from google.colab import files\n",
        "\n",
        "start_year = 1820\n",
        "end_year = 1827 #This is end-year exclusive (I think)"
      ],
      "metadata": {
        "id": "Fy1ZCAu_twkf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Cell for loading files from local drive\n",
        "kw_file = files.upload()\n",
        "\n",
        "# Specify custom column names\n",
        "column_names = [\"kword\", \"kwyear\"]\n",
        "\n",
        "# Read the uploaded CSV file into a DataFrame with custom column names\n",
        "for fn in kw_file.keys():\n",
        "    kw_df = pd.read_csv(fn, names=column_names, header=None)\n",
        "\n",
        "# Display information about the uploaded file\n",
        "for fn in kw_file.keys():\n",
        "    print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "          name=fn, length=len(kw_file[fn])))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 39
        },
        "id": "IudtCh2We58L",
        "outputId": "2e9ab1e3-5eb0-4531-c2f2-404c98c82dc2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8329fb97-c2b9-466a-92a5-5d0bf1b11580\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8329fb97-c2b9-466a-92a5-5d0bf1b11580\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining function to load dataset\n",
        "\n",
        "def load_text_dataset(dataset_year_str):\n",
        "    \"\"\"\n",
        "    This function pulls a dataset of a specific year from the HuggingFace Hub.\n",
        "\n",
        "    Parameters:\n",
        "        dataset_year (int): The year of the dataset to be pulled..\n",
        "\n",
        "    Returns:\n",
        "        dataset_article_level: dataset for appropriate year\n",
        "    \"\"\"\n",
        "    # Download data for the dataset year at the associated article level (Default)\n",
        "    # dataset = load_dataset(\"dell-research-harvard/AmericanStories\", \"subset_years\", year_list=[dataset_year])\n",
        "\n",
        "    # now let's load our data, we have to specify the huggingface location of our\n",
        "    # data, the fact that we want to have a subset of years, and our desired years\n",
        "    dataset_article_level=load_dataset(\"dell-research-harvard/AmericanStories\",\n",
        "                                      \"subset_years\",\n",
        "                                       year_list=[dataset_year_str],\n",
        "                                       trust_remote_code=True\n",
        "                                       )\n",
        "\n",
        "    return dataset_article_level"
      ],
      "metadata": {
        "id": "Ek6QpIYKyGpr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Function to filter kw data in use based on years of discovery in kw file.\n",
        "\n",
        "def get_kw(dataset_year_str):\n",
        "    \"\"\"\n",
        "    This function loads a CSV file to create a DataFrame and filters out keywords where the second column is less than 1774\n",
        "    Parameters:\n",
        "        kw_file loaded from prompt above\n",
        "    Returns:\n",
        "        pandas.DataFrame: The filtered Data\n",
        "    \"\"\"\n",
        "    # Convert dataset_year to integer\n",
        "    dataset_year = int(dataset_year_str)\n",
        "\n",
        "    # Filter the rows based on the condition\n",
        "    kw_df_filter = kw_df[kw_df['kwyear'] <= dataset_year]\n",
        "\n",
        "    # print(kw_df_filter)\n",
        "\n",
        "    return kw_df_filter\n",
        "\n"
      ],
      "metadata": {
        "id": "-SvYzj3t89IX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def process_kw(dataset_year_str, kw_df_filter, dataset_article_level):\n",
        "    \"\"\"\n",
        "    This function processes words in a DataFrame.\n",
        "\n",
        "    Parameters:\n",
        "        kw_df_filter (pandas.DataFrame): The DataFrame containing keywords\n",
        "        dataset_article (DatasetDict): A dictionary-like object containing datasets for different years.\n",
        "\n",
        "    Returns:\n",
        "        dataset_year_hits (DataFrame or None): A DataFrame containing results if found, or None if no results were found.\n",
        "    \"\"\"\n",
        "    # Creating an empty dataframe\n",
        "    current_year_df = pd.DataFrame()\n",
        "\n",
        "    for index, row in kw_df_filter.iterrows():\n",
        "        explore_kw = row.iloc[0]\n",
        "        result_df = kw_pair_search(dataset_article_level, dataset_year_str, explore_kw)\n",
        "        # Concatenate the single search result onto the results DataFrame\n",
        "        current_year_df = pd.concat([current_year_df, result_df], ignore_index=True)\n",
        "\n",
        "    return current_year_df\n"
      ],
      "metadata": {
        "id": "Mf7CjY-AznRZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def kw_pair_search(dataset_article, dataset_year, explor_kw):\n",
        "    \"\"\"\n",
        "    This function searches through the dataset, by kw, to look for matching articles.\n",
        "\n",
        "    Parameters:\n",
        "        dataset_article (DatasetDict): A dictionary-like object containing datasets for different years.\n",
        "        dataset_year (int): The year of the dataset.\n",
        "        explor_kw (str): The keyword to search for.\n",
        "\n",
        "    Returns:\n",
        "        df_of_articles_containing_two_words (DataFrame): A DataFrame containing article IDs and article texts of articles containing both keywords.\n",
        "    \"\"\"\n",
        "    # Access the dataset for the specific year\n",
        "    year_dataset = dataset_article[dataset_year]\n",
        "\n",
        "    # Access the 'raw_data_string' column\n",
        "    articles = year_dataset['article']\n",
        "\n",
        "    # Create empty list to store matching articles\n",
        "    articles_containing_two_words = []\n",
        "\n",
        "    for article_n, article_text in enumerate(articles):\n",
        "        article_text = article_text.lower()\n",
        "        if \"explor\" in article_text and explor_kw in article_text:\n",
        "            # Append the matching article information to the list\n",
        "            articles_containing_two_words.append({\n",
        "                'article_year': dataset_year,\n",
        "                'keyword hit': explor_kw,\n",
        "                'row_number': article_n,\n",
        "                'article_ID': dataset_article[dataset_year][article_n][\"article_id\"],\n",
        "                'newspaper_name': dataset_article[dataset_year][article_n][\"newspaper_name\"],\n",
        "                'edition': dataset_article[dataset_year][article_n][\"edition\"],\n",
        "                'date': dataset_article[dataset_year][article_n][\"date\"],\n",
        "                'page': dataset_article[dataset_year][article_n][\"page\"],\n",
        "                'headline': dataset_article[dataset_year][article_n][\"headline\"],\n",
        "                'byline': dataset_article[dataset_year][article_n][\"byline\"],\n",
        "                # 'article': dataset_article[dataset_year][article_n][\"article_id\"],\n",
        "            })\n",
        "\n",
        "    # Convert the list of dictionaries to a DataFrame\n",
        "    df_of_articles_containing_two_words = pd.DataFrame(articles_containing_two_words)\n",
        "    # if not df_of_articles_containing_two_words.empty:\n",
        "    #  print(df_of_articles_containing_two_words)\n",
        "    # input(\"Press Enter to continue...\")\n",
        "    return df_of_articles_containing_two_words"
      ],
      "metadata": {
        "id": "mVewWmA8BqHK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = pd.DataFrame()\n",
        "\n",
        "for loop_year in range(start_year, end__year):\n",
        "    dataset_year_str = str(loop_year)\n",
        "    try:\n",
        "        # Load dataset for current loop_year\n",
        "        dataset_article_level = load_text_dataset(dataset_year_str)\n",
        "\n",
        "        # Get valid keyword filters for current year\n",
        "        kw_df_filter = get_kw(loop_year)\n",
        "        # print (\"Processing year\", dataset_year_str)\n",
        "\n",
        "        # Process keyword filters and dataset for current loop year to get hits\n",
        "        year_search_result = process_kw(dataset_year_str,kw_df_filter, dataset_article_level)\n",
        "\n",
        "        # if not year_search_result.empty:\n",
        "        #    print(year_search_result)\n",
        "\n",
        "\n",
        "        # Concatenate the single search result onto the results DataFrame\n",
        "        results = pd.concat([results, year_search_result])\n",
        "\n",
        "    except ValueError:\n",
        "        print(f\"Dataset empty for {dataset_year_str}. Moving to the next year.\")\n",
        "        continue\n",
        "\n",
        "results = results.reset_index(drop=True)\n",
        "results.to_csv('AS_Explor_KW_Hits_Raw.csv', index=False)\n",
        "files.download(\"AS_Explor_KW_Hits_Raw.csv\")\n",
        "print(\"Finished\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUp2-Y38I1S7",
        "outputId": "0106ed3a-0fd6-4d45-c74e-3f161947e59a",
        "collapsed": true
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = results.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "kW85hKicF3Lj"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sq5PxGbcTV7",
        "outputId": "a3814ab0-73c4-4f41-9334-2b19c205f686",
        "collapsed": true
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   article_year keyword hit  row_number  \\\n",
            "0          1821        mars         182   \n",
            "1          1821        star          58   \n",
            "2          1822    astronom         224   \n",
            "3          1822    herschel         224   \n",
            "4          1822       space         224   \n",
            "5          1823      heaven         513   \n",
            "6          1823        mars        1044   \n",
            "7          1823      planet         513   \n",
            "8          1823       space         513   \n",
            "9          1823        star         176   \n",
            "10         1823        star        1034   \n",
            "11         1824      heaven         482   \n",
            "12         1824        mars         325   \n",
            "13         1824        moon         909   \n",
            "14         1824        moon        1018   \n",
            "15         1824        star         482   \n",
            "16         1825    astronom         190   \n",
            "17         1825       comet        1951   \n",
            "18         1825      heaven        1951   \n",
            "19         1825      heaven        3614   \n",
            "20         1825       space        1951   \n",
            "21         1825        star        2431   \n",
            "22         1826        moon        1193   \n",
            "\n",
            "                                           article_ID  \\\n",
            "0   47_1821-04-03_pNone_sn83016083_00332895102_182...   \n",
            "1   6_1821-04-03_p1_sn83016083_00332895102_1821040...   \n",
            "2   1_1822-10-15_p3_sn83016083_00332895102_1822101...   \n",
            "3   1_1822-10-15_p3_sn83016083_00332895102_1822101...   \n",
            "4   1_1822-10-15_p3_sn83016083_00332895102_1822101...   \n",
            "5   13_1823-11-20_p4_sn88053079_00271740244_182311...   \n",
            "6   10_1823-09-25_p3_sn88053079_00271740244_182309...   \n",
            "7   13_1823-11-20_p4_sn88053079_00271740244_182311...   \n",
            "8   13_1823-11-20_p4_sn88053079_00271740244_182311...   \n",
            "9   13_1823-09-18_p1_sn88053079_00271740244_182309...   \n",
            "10  14_1823-11-27_p2_sn88053079_00271740244_182311...   \n",
            "11  2_1824-10-28_p1_sn88053080_00271740244_1824102...   \n",
            "12  19_1824-07-01_p3_sn88053080_00271740244_182407...   \n",
            "13  15_1824-10-14_p1_sn88053080_00271740244_182410...   \n",
            "14  19_1824-07-08_p3_sn88053080_00271740244_182407...   \n",
            "15  2_1824-10-28_p1_sn88053080_00271740244_1824102...   \n",
            "16  2_1825-12-09_p3_sn82014894_00271740207_1825120...   \n",
            "17  3_1825-11-10_p1_sn85042523_00271740244_1825111...   \n",
            "18  3_1825-11-10_p1_sn85042523_00271740244_1825111...   \n",
            "19  4_1825-07-21_p1_sn88053080_00271740244_1825072...   \n",
            "20  3_1825-11-10_p1_sn85042523_00271740244_1825111...   \n",
            "21  8_1825-10-27_p2_sn88053080_00271740244_1825102...   \n",
            "22  3_1826-08-03_p1_sn85042523_00271740244_1826080...   \n",
            "\n",
            "                                 newspaper_name edition        date   page  \\\n",
            "0                         The Portland gazette.      01  1821-04-03  pNone   \n",
            "1                         The Portland gazette.      01  1821-04-03     p1   \n",
            "2                         The Portland gazette.      01  1822-10-15     p3   \n",
            "3                         The Portland gazette.      01  1822-10-15     p3   \n",
            "4                         The Portland gazette.      01  1822-10-15     p3   \n",
            "5                            The Wilmingtonian.      01  1823-11-20     p4   \n",
            "6                            The Wilmingtonian.      01  1823-09-25     p3   \n",
            "7                            The Wilmingtonian.      01  1823-11-20     p4   \n",
            "8                            The Wilmingtonian.      01  1823-11-20     p4   \n",
            "9                            The Wilmingtonian.      01  1823-09-18     p1   \n",
            "10                           The Wilmingtonian.      01  1823-11-27     p2   \n",
            "11    The Wilmingtonian, and Delaware register.      01  1824-10-28     p1   \n",
            "12    The Wilmingtonian, and Delaware register.      01  1824-07-01     p3   \n",
            "13    The Wilmingtonian, and Delaware register.      01  1824-10-14     p1   \n",
            "14    The Wilmingtonian, and Delaware register.      01  1824-07-08     p3   \n",
            "15    The Wilmingtonian, and Delaware register.      01  1824-10-28     p1   \n",
            "16   American watchman and Delaware advertiser.      01  1825-12-09     p3   \n",
            "17  The Wilmingtonian, and Delaware advertiser.      01  1825-11-10     p1   \n",
            "18  The Wilmingtonian, and Delaware advertiser.      01  1825-11-10     p1   \n",
            "19    The Wilmingtonian, and Delaware register.      01  1825-07-21     p1   \n",
            "20  The Wilmingtonian, and Delaware advertiser.      01  1825-11-10     p1   \n",
            "21    The Wilmingtonian, and Delaware register.      01  1825-10-27     p2   \n",
            "22  The Wilmingtonian, and Delaware advertiser.      01  1826-08-03     p1   \n",
            "\n",
            "                                             headline byline  \n",
            "0                                                             \n",
            "1                                         MISCELLANY.         \n",
            "2                                                             \n",
            "3                                                             \n",
            "4                                                             \n",
            "5   From the New York Patriot.\\nHymn to the Spirit...         \n",
            "6               ron THE wILmINGToNIAN.\\n\\nGentlemen.-         \n",
            "7   From the New York Patriot.\\nHymn to the Spirit...         \n",
            "8   From the New York Patriot.\\nHymn to the Spirit...         \n",
            "9             From Longs Expedition.\\nDOCTOR BALDWIN.         \n",
            "10  NORTH WEST EXPEDITION.\\n\\n\\nauthentic Particul...         \n",
            "11                            \" THE DAMrER\"-AFRAaaEsT         \n",
            "12                      Foreign & Domestic Gleanings.         \n",
            "13                                      WHOLE No. So.         \n",
            "14                                                            \n",
            "15                            \" THE DAMrER\"-AFRAaaEsT         \n",
            "16                                                            \n",
            "17                                                            \n",
            "18                                                            \n",
            "19                                                            \n",
            "20                                                            \n",
            "21                                                            \n",
            "22                           A DREAM OF THE PYRAMIDS.         \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "foo=load_text_dataset(\"1827\")"
      ],
      "metadata": {
        "id": "Qv98VoTrdq28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"AS_Explor_KW_Hits_Raw.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "KHL5hKbBR8cr",
        "outputId": "1816bff4-cf51-48b9-f3aa-314350002aa5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0233bb7a-02c8-48ed-ae3c-4953bf178271\", \"AS_Explor_KW_Hits_Raw.csv\", 3357)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pg_JqwMNIsaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***SOLVENT FRONT\n",
        "\n",
        "Code above this line has been rechecked against AmStories and works properly.***"
      ],
      "metadata": {
        "id": "njhvRm39ElEc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining Functions\n",
        "\n",
        "# Def Load Text Dataset\n",
        "# Def Process = Search on two keywords\n",
        "# AmStory light cleanup\n",
        "# GPT OCR Cleanup\n",
        "# GPT Explore space\n",
        "# Evaluate explore space (for multiple runs)\n",
        "# Sort by vote counts into six pops (5Y, 0N - 4/1, 3/2, 2/3, 1/4, 0/5)"
      ],
      "metadata": {
        "id": "LoC3vAt4tzEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining Functions\n",
        "\n",
        "*1.  Def Load Dataset*\n",
        "\n",
        "*2.  Def Process = Search on two keywords*\n",
        "3.  GPT OCR Cleanup\n",
        "4.  GPT Explore space\n",
        "5.  Evaluate explore space (for multiple runs)\n",
        "6.  Sort by vote counts into six pops (5Y, 0N - 4/1, 3/2, 2/3, 1/4, 0/5)\n",
        "7.  Match with coded results\n",
        "8.  Validate"
      ],
      "metadata": {
        "id": "uwuKrrPExW3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating an empty dataframe based on the features of the dataset\n",
        "\n",
        "# Assuming dataset_article_level[\"1862\"].features is a dictionary\n",
        "features_dict = dataset_article_level[dataset_year_str].features\n",
        "\n",
        "# Create a DataFrame from the dictionary\n",
        "current_year_df = pd.DataFrame([features_dict])\n"
      ],
      "metadata": {
        "id": "fXbM3cbPFtSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loop\n",
        "\n",
        "  #For each year in range\n",
        "     #Load dataset, and then process\n",
        "        #Process loop on keywords\n",
        "        #Save to file\n",
        "\n",
        "#Save to file (checkpoint for raw explor corpus)\n",
        "\n",
        "# Mechanics for next pending size\n",
        "# Run light AmStory cleanup\n",
        "# Run GPT OCR cleanup\n",
        "# Run 5x explore space decision via GPT\n",
        "# Split out results based on similar votes\n",
        "# Add in links to existing coding responses\n",
        "# Validate decisions (maybe sample of yes/no and some larger portion of mixed votes to get a feel for data)\n",
        "\n",
        "# Analysis?  Decide next steps?  Consider Hathi Dictionary run?\n"
      ],
      "metadata": {
        "id": "ccFuAdVKt1xd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first few rows of the DataFrame to inspect the data\n",
        "print(\"First few rows of the DataFrame:\")\n",
        "print(results.head())\n",
        "\n",
        "# Get the shape of the DataFrame\n",
        "print(\"\\nShape of the DataFrame:\")\n",
        "print(results.shape)\n",
        "\n",
        "# Get the data types of each column in the DataFrame\n",
        "print(\"\\nData types of each column:\")\n",
        "print(results.dtypes)\n",
        "\n",
        "# Optionally, you can get a concise summary of the DataFrame\n",
        "print(\"\\nSummary of the DataFrame:\")\n",
        "print(results.info())"
      ],
      "metadata": {
        "id": "ac_5TSyK9GNs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}